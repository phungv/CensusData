{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlrd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_names = ['ak',\t'al',\t'ar',\t'az',\t'ca',\t'co',\t'ct',\t'dc',\t'de',\n",
    "'fl',\t'ga',\t'hi',\t'ia',\t'id',\t'il',\t'in',\t'ks',\t'ky',\n",
    "'la',\t'ma',\t'md',\t'me',\t'mi',\t'mn',\t'mo',\t'ms',\t'mt',\n",
    "'nc',\t'nd',\t'ne',\t'nh',\t'nj',\t'nm',\t'nv',\t'ny',\t'oh',\n",
    "'ok',\t'or',\t'pa',\t'pr',\t'ri',\t'sc',\t'sd',\t'tn',\t'tx',\n",
    "'us',\t'ut',\t'va',\t'vt',\t'wa',\t'wi',\t'wv',\t'wy'\t\n",
    "]\n",
    "dfs = pd.read_excel(r\"C:\\Census Data\\References\\5_year_Mini_Geo.xlsx\", sheet_name=sheet_names)\n",
    "LogRecRef = pd.concat((df.assign(source=sheet) for sheet, df in dfs.items()), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>LOGRECNO</th>\n",
       "      <th>Geography ID</th>\n",
       "      <th>Geography Name</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>1</td>\n",
       "      <td>04000US02</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>ak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>2</td>\n",
       "      <td>04001US02</td>\n",
       "      <td>Alaska -- Urban</td>\n",
       "      <td>ak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>3</td>\n",
       "      <td>04043US02</td>\n",
       "      <td>Alaska -- Rural</td>\n",
       "      <td>ak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>4</td>\n",
       "      <td>040A0US02</td>\n",
       "      <td>Alaska -- In metropolitan or micropolitan stat...</td>\n",
       "      <td>ak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>5</td>\n",
       "      <td>040C0US02</td>\n",
       "      <td>Alaska -- In metropolitan statistical area</td>\n",
       "      <td>ak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STATE  LOGRECNO Geography ID  \\\n",
       "0    AK         1    04000US02   \n",
       "1    AK         2    04001US02   \n",
       "2    AK         3    04043US02   \n",
       "3    AK         4    040A0US02   \n",
       "4    AK         5    040C0US02   \n",
       "\n",
       "                                      Geography Name source  \n",
       "0                                             Alaska     ak  \n",
       "1                                    Alaska -- Urban     ak  \n",
       "2                                    Alaska -- Rural     ak  \n",
       "3  Alaska -- In metropolitan or micropolitan stat...     ak  \n",
       "4         Alaska -- In metropolitan statistical area     ak  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogRecRef.rename(columns = {\"Logical Record Number\":\"LOGRECNO\", \"State\":\"STATE\"}, inplace = True)\n",
    "LogRecRef.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set to the file extension of \"to-be-merged\" files\n",
    "ext = \".txt\"\n",
    "#set to your working directory\n",
    "dir_path = 'C:\\\\Census Data\\\\data'\n",
    "#set to the name of your output file\n",
    "#results = 'ACSSF_2012_2016_Full.txt'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "files = os.listdir('C:\\\\Census Data\\\\data')\n",
    "\n",
    "#e20161ak0001000\n",
    "#e = estimates\n",
    "#2016 = year\n",
    "#1 = 1 year estimate vs. 5 year\n",
    "#ak = state\n",
    "#0001 = sequence number\n",
    "#000 = iterationID\n",
    "\n",
    "files2 = [k for k in files if 'e' in k] \n",
    "#files3 = [k for k in files2 if '0041' in k] #value\n",
    "files3a = [k for k in files2 if 'e20175' in k]\n",
    "\n",
    "\n",
    "string = 'C:\\\\Census Data\\\\data\\\\'\n",
    "counter_Files = [string + x for x in files3a]\n",
    "#files4\n",
    "\n",
    "#for (i, value) in enumerate(files4):\n",
    "\n",
    "    #C:\\Census Data\\data\\e20165ak0001000\n",
    "    \n",
    "\n",
    "#'0041'\n",
    "#C:\\Census Data\\References\\2016_5yr_Summary_FileTemplates\\templates\\Seq41.xls\n",
    "#\"csvfile41.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001\n",
      "r\"C:\\Census Data\\References\\2017_5yr_Summary_FileTemplates\\xls_temp\\Seq1.xlsx\n",
      "r\"csvfile1.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'r\"csvfile1.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for (i) in range(1,2):\n",
    "    \n",
    "    seqcount = \"000\"+str(i)        \n",
    "    lseqcount = seqcount[::-1][:4][::-1]\n",
    "\n",
    "    print(lseqcount)\n",
    "    \n",
    "    Seqfile = 'r\"'+r\"C:\\Census Data\\References\\2017_5yr_Summary_FileTemplates\\xls_temp\\Seq\" + str(i) + \".xlsx\"\n",
    "    \n",
    "    print(Seqfile)\n",
    "    \n",
    "    CSVfile = 'r\"'+r\"csvfile\" + str(i) + \".csv\"\n",
    "    \n",
    "    print(CSVfile)\n",
    "    \n",
    "    \n",
    "\n",
    "#C:\\Census Data\\References\\2016_5yr_Summary_FileTemplates\\templates\\Seq41.xls\n",
    "#\"csvfile41.csv\"    \n",
    "    \n",
    "#'0041'  \n",
    "CSVfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fullfile = pd.read_csv('C:\\\\Census Data\\\\data\\\\e20175ma0008000.txt', names=my_cols, sep=',', engine='python')\n",
    "#fullfile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csvfile1.csv\n",
      "csvfile2.csv\n",
      "csvfile3.csv\n",
      "csvfile4.csv\n",
      "csvfile5.csv\n",
      "csvfile6.csv\n",
      "csvfile7.csv\n",
      "csvfile8.csv\n",
      "csvfile9.csv\n",
      "csvfile10.csv\n",
      "csvfile11.csv\n",
      "csvfile12.csv\n",
      "csvfile13.csv\n",
      "csvfile14.csv\n",
      "csvfile15.csv\n",
      "csvfile16.csv\n",
      "csvfile17.csv\n",
      "csvfile18.csv\n",
      "csvfile19.csv\n",
      "csvfile20.csv\n",
      "csvfile21.csv\n",
      "csvfile22.csv\n",
      "csvfile23.csv\n",
      "csvfile24.csv\n",
      "csvfile25.csv\n",
      "csvfile26.csv\n",
      "csvfile27.csv\n",
      "csvfile28.csv\n",
      "csvfile29.csv\n",
      "csvfile30.csv\n",
      "csvfile31.csv\n",
      "csvfile32.csv\n",
      "csvfile33.csv\n",
      "csvfile34.csv\n",
      "csvfile35.csv\n",
      "csvfile36.csv\n",
      "csvfile37.csv\n",
      "csvfile38.csv\n",
      "csvfile39.csv\n",
      "csvfile40.csv\n",
      "csvfile41.csv\n",
      "csvfile42.csv\n",
      "csvfile43.csv\n",
      "csvfile44.csv\n",
      "csvfile45.csv\n",
      "csvfile46.csv\n",
      "csvfile47.csv\n",
      "csvfile48.csv\n",
      "csvfile49.csv\n",
      "csvfile50.csv\n",
      "csvfile51.csv\n",
      "csvfile52.csv\n",
      "csvfile53.csv\n",
      "csvfile54.csv\n",
      "csvfile55.csv\n",
      "csvfile56.csv\n",
      "csvfile57.csv\n",
      "csvfile58.csv\n",
      "csvfile59.csv\n",
      "csvfile60.csv\n",
      "csvfile61.csv\n",
      "csvfile62.csv\n",
      "csvfile63.csv\n",
      "csvfile64.csv\n",
      "csvfile65.csv\n",
      "csvfile66.csv\n",
      "csvfile67.csv\n",
      "csvfile68.csv\n",
      "csvfile69.csv\n",
      "csvfile70.csv\n",
      "csvfile71.csv\n",
      "csvfile72.csv\n",
      "csvfile73.csv\n",
      "csvfile74.csv\n",
      "csvfile75.csv\n",
      "csvfile76.csv\n",
      "csvfile77.csv\n",
      "csvfile78.csv\n",
      "csvfile79.csv\n",
      "csvfile80.csv\n",
      "csvfile81.csv\n",
      "csvfile82.csv\n",
      "csvfile83.csv\n",
      "csvfile84.csv\n",
      "csvfile85.csv\n",
      "csvfile86.csv\n",
      "csvfile87.csv\n",
      "csvfile88.csv\n",
      "csvfile89.csv\n",
      "csvfile90.csv\n",
      "csvfile91.csv\n",
      "csvfile92.csv\n",
      "csvfile93.csv\n",
      "csvfile94.csv\n",
      "csvfile95.csv\n",
      "csvfile96.csv\n",
      "csvfile97.csv\n",
      "csvfile98.csv\n",
      "csvfile99.csv\n",
      "csvfile100.csv\n",
      "csvfile101.csv\n",
      "csvfile102.csv\n",
      "csvfile103.csv\n",
      "csvfile104.csv\n",
      "csvfile105.csv\n",
      "csvfile106.csv\n",
      "csvfile107.csv\n",
      "csvfile108.csv\n",
      "csvfile109.csv\n",
      "csvfile110.csv\n",
      "csvfile111.csv\n",
      "csvfile112.csv\n",
      "csvfile113.csv\n",
      "csvfile114.csv\n",
      "csvfile115.csv\n",
      "csvfile116.csv\n",
      "csvfile117.csv\n",
      "csvfile118.csv\n",
      "csvfile119.csv\n",
      "csvfile120.csv\n",
      "csvfile121.csv\n",
      "csvfile122.csv\n",
      "csvfile123.csv\n",
      "csvfile124.csv\n",
      "csvfile125.csv\n",
      "csvfile126.csv\n",
      "csvfile127.csv\n",
      "csvfile128.csv\n",
      "csvfile129.csv\n",
      "csvfile130.csv\n",
      "csvfile131.csv\n",
      "csvfile132.csv\n",
      "csvfile133.csv\n"
     ]
    }
   ],
   "source": [
    "#set to the file extension of \"to-be-merged\" files\n",
    "ext = \".txt\"\n",
    "#set to your working directory\n",
    "dir_path = 'C:\\\\Census Data\\\\data'\n",
    "#set to the name of your output file\n",
    "#results = 'ACSSF_2012_2016_Full.txt'\n",
    "\n",
    "\n",
    "\n",
    "#for number in fib:\n",
    "    \n",
    "#fib = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,\n",
    "#32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,\n",
    "#62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,\n",
    "#93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,\n",
    "#118,119,120,121,122]\n",
    "\n",
    "\n",
    "\n",
    "for (i) in range(1,134):\n",
    "    \n",
    "    seqcount = \"000\"+str(i)         \n",
    "    lseqcount = seqcount[::-1][:4][::-1] + '000'\n",
    "    #print(lseqcount)\n",
    "    \n",
    "    Seqfile = r\"C:\\Census Data\\References\\2017_5yr_Summary_FileTemplates\\xls_temp\\Seq\" + str(i) + \".xlsx\"    \n",
    "    #print(Seqfile)    \n",
    "    \n",
    "    CSVfile = r\"csvfile\" + str(i) + \".csv\"\n",
    "    #print(CSVfile)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    files = os.listdir('C:\\\\Census Data\\\\data')\n",
    "\n",
    "        #e20161ak0001000\n",
    "        #e = estimates\n",
    "        #2016 = year\n",
    "        #1 = 1 year estimate vs. 5 year\n",
    "        #ak = state\n",
    "        #0001 = sequence number\n",
    "        #000 = iterationID\n",
    "\n",
    "    files2 = [k for k in files if 'e' in k] \n",
    "    files3 = [k for k in files2 if lseqcount in k] \n",
    "    #files3b = [k for k in files3 if 'ma' in k]\n",
    "    files3a = [k for k in files3 if 'e20175' in k]\n",
    "\n",
    "\n",
    "    string = 'C:\\\\Census Data\\\\data\\\\'\n",
    "    files4 = [string + x for x in files3a]\n",
    "    files4\n",
    "\n",
    "\n",
    "\n",
    "    my_cols = [\"1\",\"YEAR\",\"STATE\",\"4\",\"SEQ\",\"LOGRECNO\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\n",
    "    \"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\n",
    "    \"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\n",
    "    \"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\n",
    "    \"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\n",
    "    \"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\n",
    "    \"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\",\"151\",\"152\",\"153\",\"154\",\"155\",\"156\",\n",
    "    \"157\",\"158\",\"159\",\"160\",\"161\",\"162\",\"163\",\"164\",\"165\",\"166\",\"167\",\"168\",\"169\",\"170\",\"171\",\"172\",\"173\",\"174\",\"175\",\"176\",\n",
    "    \"177\",\"178\",\"179\",\"180\",\"181\",\"182\",\"183\",\"184\",\"185\",\"186\",\"187\",\"188\",\"189\",\"190\",\"191\",\"192\",\"193\",\"194\",\"195\",\"196\",\n",
    "    \"197\",\"198\",\"199\",\"200\",\"201\",\"202\",\"203\",\"204\",\"205\",\"206\",\"207\",\"208\",\"209\",\"210\",\"211\",\"212\",\"213\",\"214\",\n",
    "    \"215\",\"216\",\"217\",\"218\",\"219\",\"220\",\"221\",\"222\",\"223\",\"224\",\"225\",\"226\",\"227\",\"228\",\"229\",\"230\",\"231\",\"232\",\"233\",\"234\",\n",
    "    \"235\",\"236\",\"237\",\"238\",\"239\",\"240\",\"241\",\"242\",\"243\",\"244\",\"245\",\"246\",\"247\",\"248\",\"249\",\"250\",\"251\",\"252\",\"253\",\n",
    "    \"254\",\"255\",\"256\",\"257\",\"258\",\"259\",\"260\",\"261\",\"262\",\"263\",\"264\",\"265\",\"266\",\"267\",\"268\",\"269\",\"270\",\"271\",\"272\",\n",
    "    \"273\",\"274\",\"275\",\"276\",\"277\",\"278\",\"279\",\"280\",\"281\",\"282\",\"283\",\"284\",\"285\",\"286\",\"287\",\"288\",\"289\",\"290\",\"291\",\n",
    "    \"292\",\"293\",\"294\",\"295\",\"296\",\"297\",\"298\",\"299\",\"300\",\"301\",\"302\",\"303\",\"304\",\"305\",\"306\",\"307\",\"308\",\"309\",\"310\",\"311\",\n",
    "    \"312\",\"313\",\"314\",\"315\",\"316\",\"317\",\"318\",\"319\",\"320\",\"321\",\"322\",\"323\",\"324\",\"325\",\"326\",\"327\",\"328\",\"329\",\"330\",\n",
    "    \"331\",\"332\",\"333\",\"334\",\"335\",\"336\",\"337\",\"338\",\"339\",\"340\",\"341\",\"342\",\"343\",\"344\",\"345\",\"346\",\"347\",\"348\",\"349\",\"350\",\n",
    "    \"351\",\"352\",\"353\",\"354\",\"355\",\"356\",\"357\",\"358\",\"359\",\"360\",\"361\",\"362\",\"363\",\"364\",\"365\",\"366\",\"367\",\"368\",\"369\",\"370\",\n",
    "    \"371\",\"372\",\"373\",\"374\",\"375\",\"376\",\"377\",\"378\",\"379\",\"380\",\"381\",\"382\",\"383\",\"384\",\"385\",\"386\",\"387\",\"388\",\"389\",\"390\",\n",
    "    \"391\",\"392\",\"393\",\"394\",\"395\",\"396\",\"397\",\"398\",\"399\",\"400\",\"401\",\"402\",\"403\",\"404\",\"405\",\"406\",\"407\",\"408\",\"409\",\n",
    "    \"410\",\"411\",\"412\",\"413\",\"414\",\"415\",\"416\",\"417\",\"418\",\"419\",\"420\",\"421\",\"422\",\"423\",\"424\",\"425\",\"426\",\"427\",\"428\",\"429\",\n",
    "    \"430\",\"431\",\"432\",\"433\",\"434\",\"435\",\"436\",\"437\",\"438\",\"439\",\"440\",\"441\",\"442\",\"443\",\"444\",\"445\",\"446\",\"447\",\"448\",\n",
    "    \"449\",\"450\",\"451\",\"452\",\"453\",\"454\",\"455\",\"456\",\"457\",\"458\",\"459\",\"460\",\"461\",\"462\",\"463\",\"464\",\"465\",\"466\",\"467\",\n",
    "    \"468\",\"469\",\"470\",\"471\",\"472\",\"473\",\"474\",\"475\",\"476\",\"477\",\"478\",\"479\",\"480\",\"481\",\"482\",\"483\",\"484\",\"485\",\"486\",\n",
    "    \"487\",\"488\",\"489\",\"490\",\"491\",\"492\",\"493\",\"494\",\"495\",\"496\",\"497\",\"498\",\"499\",\"500\",\"501\",\"502\",\"503\",\"504\",\"505\",\n",
    "    \"506\",\"507\",\"508\",\"509\",\"510\",\"511\",\"512\",\"513\",\"514\",\"515\",\"516\",\"517\",\"518\",\"519\",\"520\",\"521\",\"522\",\"523\",\"524\",\n",
    "    \"525\",\"526\",\"527\",\"528\",\"529\",\"530\",\"531\",\"532\",\"533\",\"534\",\"535\",\"536\",\"537\",\"538\",\"539\",\"540\",\"541\",\"542\",\"543\",\n",
    "    \"544\",\"545\",\"546\",\"547\",\"548\",\"549\",\"550\",\"551\",\"552\",\"553\",\"554\",\"555\",\"556\",\"557\"]\n",
    "\n",
    "    fullfile = pd.read_csv('C:\\\\Census Data\\\\data\\\\e20175ma0001000.txt', names=my_cols, sep=',', engine='python')\n",
    "    fullfile = fullfile.loc[fullfile['557'] == 0]\n",
    "    #fullfile\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for f in files4:\n",
    "      if f.endswith(ext):\n",
    "        data = open(f)\n",
    "\n",
    "        #out = pd.read_csv(data, names=my_cols, engine='python')\n",
    "        out = pd.read_csv(data, names=my_cols, sep=',', engine='python')\n",
    "\n",
    "        out2 = out\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        fullfile = pd.concat([fullfile, out2], sort=False, ignore_index=True)\n",
    "        \n",
    "        data.close()\n",
    "\n",
    "\n",
    "\n",
    "    fullfile[\"STATE\"] = fullfile['STATE'].str.upper() #uppercase space\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #fullfile = fullfile.dropna(axis=1, how='all')\n",
    "    fullfile2 = fullfile\n",
    "\n",
    "    #fullfile2.to_csv(\"techers.csv\", sep=',', encoding='utf-8')\n",
    "    #out\n",
    "    #fullfile\n",
    "\n",
    "\n",
    "    #Macro1\n",
    "    #columnnames = pd.read_excel(r\"C:\\Census Data\\References\\2016_5yr_Summary_FileTemplates\\templates\\Seq41.xls\", sheet_name='E')\n",
    "    columnnames = pd.read_excel(Seqfile, sheet_name='e')\n",
    "    values = {'FILEID': \"1\", 'FILETYPE': \"YEAR\", 'STUSAB': \"STATE\", \n",
    "                                    'CHARITER': \"4\",\"SEQUENCE\" : \"SEQ\", \"LOGRECNO\": \"LOGRECNO\"\n",
    "              }\n",
    "\n",
    "    \n",
    "    \n",
    "    columnnames2 = columnnames.fillna(value = values)\n",
    "    name_str = columnnames2.transpose() \n",
    "\n",
    "    fullfile2 = fullfile2.iloc[:, 0:len(columnnames2.columns)]\n",
    "    \n",
    "    fullfile2.columns = name_str.values\n",
    "    fullfile2.columns = fullfile2.columns.map(str)\n",
    "    fullfile2.columns = fullfile2.columns.str.strip().str.replace(\":\", '').str.replace(\"'\", '').str.replace(',', '').str.replace('(', '').str.replace(')', '')\n",
    "\n",
    "    fullfile2.rename(columns = {\"STUSAB\":\"STATE\"}, inplace = True)\n",
    "    \n",
    "    geofile = pd.merge(fullfile2, LogRecRef, on = ['LOGRECNO', 'STATE'], how = \"left\")\n",
    "    geofile = geofile.drop(['source'], 1)\n",
    "\n",
    "\n",
    "    #geofile.to_csv(\"csvfile.csv\" sep=',', encoding='utf-8')\n",
    "    geofile.to_csv(CSVfile, sep=',', encoding='utf-8')\n",
    "    \n",
    "    print(CSVfile)\n",
    "    #macro2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
